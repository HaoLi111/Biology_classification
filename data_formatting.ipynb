{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biological Classification problem with phenotype\n",
    "\n",
    "Note: I don't own the data. It is gitignored to protect patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"plant_traits_espece_ee.csv\")\n",
    "df.columns = ['organs', 'trait', 'trait_code', 'finer_code/detail'] + df.columns.to_list()[4:]\n",
    "df = df.transpose()\n",
    "df = df.reset_index()\n",
    "\n",
    "n = len(df.iloc[0])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# p_organs, p_trait, p_trait_code = [np.nan] * 3\n",
    "\n",
    "\n",
    "for j in range(5, n):\n",
    "    if pd.isnull(df.iloc[0, j]):\n",
    "        df.iloc[0, j] = p_organs\n",
    "    else:\n",
    "        p_organs = df.iloc[0, j]\n",
    "    \n",
    "    if pd.isnull(df.iloc[1, j]):\n",
    "        df.iloc[1, j] = p_trait\n",
    "    else:\n",
    "        p_trait = df.iloc[1, j]\n",
    "\n",
    "    if pd.isnull(df.iloc[2, j]):\n",
    "        df.iloc[2, j] = p_trait_code\n",
    "    else:\n",
    "        p_trait_code = df.iloc[2, j]\n",
    "\n",
    "\n",
    "    df.iloc[3, j] = \">\".join(map(str, (p_organs, p_trait, p_trait_code)))\n",
    "\n",
    "df.iloc[0:3,4] = np.nan\n",
    "\n",
    "\n",
    "df2 = df.iloc[3:,:]\n",
    "# df2[0] = df2[0].astype(str)\n",
    "df2.iloc[0,0] = 'organs>trait>trait_code>detail'\n",
    "new_header = df2.iloc[0]\n",
    "df2 = df2[1:] \n",
    "df2.columns = new_header\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can do some direct filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[~pd.isnull(df2['usage>usage.material>staminal.tube'].values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction(without reweighting)\n",
    "the family don't share that much info, and the result is poor due to insufficient data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_label = df2.dropna(subset='Family')\n",
    "df_w_label.iloc[:,5:] = [[df_w_label.iloc[i,j] if pd.isnull(df_w_label.iloc[i,j]) else 1 for j in range(5,n)] for i in range(len(df_w_label))]\n",
    "X = df_w_label.iloc[:,5:]\n",
    "y = df_w_label['Family']\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "m = RandomForestClassifier(n_jobs=4, random_state=3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "\n",
    "\n",
    "X_train,  X_test,y_train, y_test = train_test_split(X, y, test_size=.5, random_state=3)# stratify=y)\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "m.fit(X_train, y_train)\n",
    "y_pred = m.predict(X_test)\n",
    "y_prob = m.predict_proba(X_test)\n",
    "y_prob ={m.classes_[i]:[y_prob[j][i]for j in range(len(y_prob))] for i in range(len(m.classes_))} \n",
    "\n",
    "\n",
    "perf = accuracy_score(y_test, y_pred)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "# log_loss(y_test, y_prob)\n",
    "perf,# conf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not valid because the classifier is ignoring all missings and there is no 2 values for non nas. Here we think na= false, redo it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_label = df2.dropna(subset='Family')\n",
    "df_w_label.iloc[:,5:] = [[0 if pd.isnull(df_w_label.iloc[i,j]) else 1 for j in range(5,n)] for i in range(len(df_w_label))]\n",
    "X = df_w_label.iloc[:,5:]\n",
    "y = df_w_label['Family']\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "m = RandomForestClassifier(n_jobs=4, random_state=3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "\n",
    "\n",
    "X_train,  X_test,y_train, y_test = train_test_split(X, y, test_size=.5, random_state=3)# stratify=y)\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "m.fit(X_train, y_train)\n",
    "y_pred = m.predict(X_test)\n",
    "y_prob = m.predict_proba(X_test)\n",
    "y_prob ={m.classes_[i]:[y_prob[j][i]for j in range(len(y_prob))] for i in range(len(m.classes_))} \n",
    "\n",
    "\n",
    "perf = accuracy_score(y_test, y_pred)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "# log_loss(y_test, y_prob)\n",
    "perf,# conf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here 50% probability we get correct family, is this bad? somewhat, but remember we get more than 2 classes.\n",
    "If we have distinct rows, we can try to over fit this--which is equivalent to coding a tree.\n",
    "now we want to formulate this as stepwise question. this needs to access all the nodes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_label = df2.dropna(subset='Family')\n",
    "df_w_label.iloc[:,5:] = [[0 if pd.isnull(df_w_label.iloc[i,j]) else 1 for j in range(5,n)] for i in range(len(df_w_label))]\n",
    "X = df_w_label.iloc[:,5:]\n",
    "y = df_w_label['Family']\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "m = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "\n",
    "\n",
    "X_train,  X_test,y_train, y_test = train_test_split(X, y, test_size=.5, random_state=3)# stratify=y)\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "m.fit(X_train, y_train)\n",
    "y_pred = m.predict(X_test)\n",
    "y_prob = m.predict_proba(X_test)\n",
    "y_prob ={m.classes_[i]:[y_prob[j][i]for j in range(len(y_prob))] for i in range(len(m.classes_))} \n",
    "\n",
    "\n",
    "perf = accuracy_score(y_test, y_pred)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "# log_loss(y_test, y_prob)\n",
    "perf,# conf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of rewriting the entire structure, this is equivalent of overfitting a decision tree in sklearn(do not worry, it can stop prematurely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DecisionTreeClassifier(max_depth=1000)\n",
    "m.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code from sklearn shows the structure, we can build an *interactive  program* with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = m\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "values = clf.tree_.value\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "while len(stack) > 0:\n",
    "    # `pop` ensures each node is only visited once\n",
    "    node_id, depth = stack.pop()\n",
    "    node_depth[node_id] = depth\n",
    "\n",
    "    # If the left and right child of a node is not the same we have a split\n",
    "    # node\n",
    "    is_split_node = children_left[node_id] != children_right[node_id]\n",
    "    # If a split node, append left and right children and depth to `stack`\n",
    "    # so we can loop through them\n",
    "    if is_split_node:\n",
    "        stack.append((children_left[node_id], depth + 1))\n",
    "        stack.append((children_right[node_id], depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\n",
    "    \"The binary tree structure has {n} nodes and has \"\n",
    "    \"the following tree structure:\\n\".format(n=n_nodes)\n",
    ")\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\n",
    "            \"{space}node={node} is a leaf node with value={value}.\".format(\n",
    "                space=node_depth[i] * \"\\t\", node=i, value=values[i]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"{space}node={node} is a split node with value={value}: \"\n",
    "            \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "            \"else to node {right}.\".format(\n",
    "                space=node_depth[i] * \"\\t\",\n",
    "                node=i,\n",
    "                left=children_left[i],\n",
    "                feature=feature[i],\n",
    "                threshold=threshold[i],\n",
    "                right=children_right[i],\n",
    "                value=values[i],\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub plan:\n",
    " - we fit and save tree\n",
    " - access node and prob, align with classes\n",
    " - make an interactive python program \n",
    "\n",
    "note:\n",
    " - this indeed gives a dichotomous key, but sub tree may not always be explainable\n",
    " - this is easy and fast, and if training data is complete with no exception, you get a deterministic procedure **not just a probabilistic model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a sequence of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "property_words = set(sum(list(map(lambda s: re.split('>', s),df2.columns.tolist())), []))\n",
    "species_words = set(sum(list(map(lambda s: re.split('\\s', s),df2.iloc[:,0].values)), []))\n",
    "species_words ,property_words\n",
    "\n",
    "all_words = species_words.union(property_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also account for mistyping or synonyms. In case for so many terms, one may have misspelled. \n",
    "Make a bench mark by sorting Levishtin edit distance to account for misspelled word.\n",
    "\n",
    "let's try to see if there are 'usages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "\n",
    "query = 'usages'\n",
    "\n",
    "distances = list(map(lambda word: editdistance.eval(query, word), list(all_words)))\n",
    "\n",
    "rank = np.argsort(distances)\n",
    "for i in range(5):\n",
    "    print(list(all_words)[rank[i]], distances[rank[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can also do a spell check with this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"usages\", \"usage\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
